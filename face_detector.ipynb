{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_detector.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM9uoR6Z0MFGso6bB090MVE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9dldQLOwoFZt","colab_type":"text"},"source":["# Instructions to run this script\n","1) It should be run in a computer with GPU. It is better to run it in Google Colab, if so, please create a shortcut of the shared folder in your drive.\n","\n","2) Locate this file \"people_counter.ipynb\" in a folder.\n","\n","3) Put your videos that you want to process in a folder.\n","\n","4) Create a folder for output videos.\n","\n","5) Mount Drive\n","\n","6) Set your default path\n","\n","7) Install the library \"face_recognition\"\n","\n","8) Run \"People Counter\"\n"]},{"cell_type":"markdown","metadata":{"id":"_uWSxX-wSTsH","colab_type":"text"},"source":["# Mount Drive"]},{"cell_type":"code","metadata":{"id":"E4THPZ0p-CRk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595881122099,"user_tz":-120,"elapsed":23265,"user":{"displayName":"Rasha Tolba","photoUrl":"","userId":"00422299242181280912"}},"outputId":"3709d4be-e8a1-49a3-99aa-eb54bd878fcd"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ikjeyEe29Kkd","colab_type":"text"},"source":["# Set Default Directory"]},{"cell_type":"code","metadata":{"id":"RnUMIWSyb6Z6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595881425522,"user_tz":-120,"elapsed":1714,"user":{"displayName":"Rasha Tolba","photoUrl":"","userId":"00422299242181280912"}},"outputId":"12db8354-5347-4d8a-df89-6fbf1b8cbc2c"},"source":["import os\n","!ls \"drive/My Drive/people-counter/Maxplank\"\n","os.chdir(\"drive/My Drive/people-counter/Maxplank\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["face_detector.ipynb  input_videos  output_videos\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JpKS_zug-xKY","colab_type":"text"},"source":["# Install Libraries"]},{"cell_type":"code","metadata":{"id":"YXil0X3T9Niz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1595881624568,"user_tz":-120,"elapsed":3311,"user":{"displayName":"Rasha Tolba","photoUrl":"","userId":"00422299242181280912"}},"outputId":"bb5e9cda-589b-420b-ad35-6876ede688ea"},"source":["!pip install face_recognition"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LxMepw6W9Uyp","colab_type":"text"},"source":["# People Counter"]},{"cell_type":"code","metadata":{"id":"_m6m_RYD9XRC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595883560671,"user_tz":-120,"elapsed":1879281,"user":{"displayName":"Rasha Tolba","photoUrl":"","userId":"00422299242181280912"}},"outputId":"259c4de6-96b1-4cb6-af40-a04546016718"},"source":["# Import libraries\n","import glob\n","import os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import face_recognition\n","\n","class Count_Person:\n","  #Initialize my class by giving the : \n","    # 1) paths of input videos\n","    # 2) paths ofoutput videos \n","    # 3) Name of cvs file where the name of each video and how many people contains\n","    # 4) Threshold to assure unique identity of a person recognition\n","    # 5) skip_frame to do the processing faster\n","\n","  def __init__(self, dir_input, dir_output, output_file_name,  threshold, skip_frame):\n","    # Function to initialize class parameters\n","    self.dir_input = dir_input\n","    self.dir_output = dir_output\n","    self.output_file_name = output_file_name\n","    self.threshold = threshold\n","    self.skip_frame=skip_frame\n","\n","  def retrieve_list_videos(self):\n","    #Function to retrieve a list of videos name stored in a given directory\n","    list_videos=os.listdir(self.dir_input)\n","    return list_videos\n","\n","  def detect_count_people(self, myinput_video):\n","    #Function to return number of people in a given video\n","    output_movie=self.dir_output+myinput_video[:-4]+\".avi\"\n","\n","    input_movie = cv2.VideoCapture(self.dir_input+myinput_video)\n","    length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(\"\\t\"+self.dir_input+myinput_video)\n","    # Initialize variables\n","    face_locations = []\n","    face_encodings = []\n","    all_face_encodings=[]\n","    face_names = []\n","    frame_number = 0\n","    writer = None\n","    while True:\n","      # Grab a single frame of video\n","      ret, frame = input_movie.read()\n","      frame_number += 1\n","\n","      # Quit when the input video file ends\n","      if not ret:\n","          break\n","      if frame_number % self.skip_frame==0:\n","        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n","        h, w, chan=frame.shape                  #Get current frame size\n","        frame=cv2.resize(frame, (w+500, h+500)) #Resize each frame\n","        rgb_frame = frame[:, :, ::-1]\n","        \n","        # Find all the faces and face encodings in the current frame of video\n","        face_locations = face_recognition.face_locations(rgb_frame, model=\"cnn\")\n","        #face_locations = face_recognition.face_locations(rgb_frame, number_of_times_to_upsample=2, model=\"cnn\")\n","        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n","        # Loop through each face found in the unknown frame\n","        found=0\n","        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n","          if len(all_face_encodings)!=0:\n","            for ii in range(len(all_face_encodings)):\n","              face_distance = face_recognition.face_distance([all_face_encodings[ii]], face_encoding)\n","              #print(face_distance)\n","              if face_distance[0] <=self.threshold :  # faces with a distance of threshold (0.65) or less should be a match.\n","                found=1\n","                continue\n","          # Draw a box around the face\n","          cv2.rectangle(frame, (left-20, top-20), (right+20, bottom+20), (0, 0, 255), 2)\n","\n","          # Draw a label with a name below the face\n","          #cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n","          #font = cv2.FONT_HERSHEY_DUPLEX\n","          #cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n","\n","          if found==0:\n","            all_face_encodings.append(face_encoding)     \n","\n","        # Write the resulting image to the output video file\n","        if frame_number%100==0:\n","          print(\"\\tWriting frame {} / {}\".format(frame_number, length))\n","        (h, w) = rgb_frame.shape[:2]\n","        if output_movie is not None and writer is None:\n","          fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","          writer = cv2.VideoWriter(output_movie, fourcc, 30, (w, h), True)\n","        if writer is not None:\n","          writer.write(frame)\n","    # All done!\n","    input_movie.release()\n","    cv2.destroyAllWindows()\n","    #Change video format\n","    #!ffmpeg -i output_movie self.dir_output+myinput_video[:-4]+\".mp4\"\n","    no_people=len(all_face_encodings)\n","    print(\"\\t[INFO] # unique person: {}\".format(no_people))\n","    return (no_people)\n","\n","  def create_csv_file(self, videos_list, list_no_people ):\n","    #Function recieve the list of videos and the q\n","    zippedList =  list(zip(videos_list, list_no_people))\n","    df=pd.DataFrame(zippedList, columns = ['Video' , 'No. of People'])\n","    df.index += 1 \n","    df.to_csv(self.dir_output+self.output_file_name)\n","  \n","  def print_cvs_file(self):\n","    #Function to print out the cvs content\n","    df=pd.read_csv(self.dir_output+self.output_file_name)\n","    print(df.head(50))\n","\n","def main():\n","    print(\"Hello to people detection and counting!\")\n","    #######  Initialize variables #######\n","    dir_input=\"input_videos/\"\n","    dir_output=\"output_videos/\"\n","    output_file_name=\"data.csv\"\n","    threshold=0.65\n","    skip_frame=2\n","    list_no_people=list()\n","    ###### Initialize class variable ######\n","    cp=Count_Person(dir_input, dir_output, output_file_name,  threshold, skip_frame)\n","    ###### Retrieve the list of video in a given directory ######\n","    videoslist=cp.retrieve_list_videos()\n","    print(\"\\n Here is the list of videos that I am going to process:\")\n","    print(videoslist)\n","    print(\"\\n ########## Processing \"+str(len(videoslist))+\" videos #########\" )\n","    for myvideo in range(len(videoslist)):\n","      print(\"\\n=========>> \"+videoslist[myvideo]+\" <<==========\")\n","      no_people=cp.detect_count_people(videoslist[myvideo])\n","      list_no_people.append(no_people)\n","      \n","    ###### Write results to a CSV file  ######\n","    cp.create_csv_file(videoslist, list_no_people)\n","\n","    ##### Print the content of the CSV file #####\n","    cp.print_cvs_file()\n","\n","    print(\"Good bye!\")\n","    \n","if __name__ == \"__main__\":\n","    main()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Hello to people detection and counting!\n","\n"," Here is the list of videos that I am going to process:\n","['video2.mp4', 'video3.mp4', 'video1.mp4']\n","\n"," ########## Processing 3 videos #########\n","\n","=========>> video2.mp4 <<==========\n","\tinput_videos/video2.mp4\n","\tWriting frame 100 / 2144\n","\tWriting frame 200 / 2144\n","\tWriting frame 300 / 2144\n","\tWriting frame 400 / 2144\n","\tWriting frame 500 / 2144\n","\tWriting frame 600 / 2144\n","\tWriting frame 700 / 2144\n","\tWriting frame 800 / 2144\n","\tWriting frame 900 / 2144\n","\tWriting frame 1000 / 2144\n","\tWriting frame 1100 / 2144\n","\tWriting frame 1200 / 2144\n","\tWriting frame 1300 / 2144\n","\tWriting frame 1400 / 2144\n","\tWriting frame 1500 / 2144\n","\tWriting frame 1600 / 2144\n","\tWriting frame 1700 / 2144\n","\tWriting frame 1800 / 2144\n","\tWriting frame 1900 / 2144\n","\tWriting frame 2000 / 2144\n","\tWriting frame 2100 / 2144\n","\t[INFO] # unique person: 4\n","\n","=========>> video3.mp4 <<==========\n","\tinput_videos/video3.mp4\n","\tWriting frame 100 / 2199\n","\tWriting frame 200 / 2199\n","\tWriting frame 300 / 2199\n","\tWriting frame 400 / 2199\n","\tWriting frame 500 / 2199\n","\tWriting frame 600 / 2199\n","\tWriting frame 700 / 2199\n","\tWriting frame 800 / 2199\n","\tWriting frame 900 / 2199\n","\tWriting frame 1000 / 2199\n","\tWriting frame 1100 / 2199\n","\tWriting frame 1200 / 2199\n","\tWriting frame 1300 / 2199\n","\tWriting frame 1400 / 2199\n","\tWriting frame 1500 / 2199\n","\tWriting frame 1600 / 2199\n","\tWriting frame 1700 / 2199\n","\tWriting frame 1800 / 2199\n","\tWriting frame 1900 / 2199\n","\tWriting frame 2000 / 2199\n","\tWriting frame 2100 / 2199\n","\t[INFO] # unique person: 13\n","\n","=========>> video1.mp4 <<==========\n","\tinput_videos/video1.mp4\n","\t[INFO] # unique person: 0\n","   Unnamed: 0       Video  No. of People\n","0           1  video2.mp4              4\n","1           2  video3.mp4             13\n","2           3  video1.mp4              0\n","Good bye!\n"],"name":"stdout"}]}]}